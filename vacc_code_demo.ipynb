{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5831d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mayleencortez/Desktop/Spring 2021/ORSuite/or_suite/envs/ambulance\n",
      "/Users/mayleencortez/Desktop/Spring 2021/ORSuite/or_suite/envs\n"
     ]
    }
   ],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "CONFIG = or_suite.envs.env_configs.vaccine_4groups_default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91546506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making an instance of the environment\n",
    "env = gym.make('Vaccine-v0', config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b042c6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2490 2490 2490 2490   10   10   10   10    0    0]\n",
      "Discrete(25)\n",
      "MultiDiscrete([10001 10001 10001 10001 10001 10001 10001 10001 10001 10001 10001])\n"
     ]
    }
   ],
   "source": [
    "print(env.state)\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9998d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the step function\n",
    "newState, reward,  done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec13c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 390  274 1411 1286   17    9    2   26   22    8 6399]\n",
      "-6399\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc5f989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached a disease-free state on day 3.9179497809214285\n"
     ]
    }
   ],
   "source": [
    "newState, reward,  done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9116d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 349  253 1317 1186    0    0    0    0    0    0   59]\n",
      "-59\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-passport",
   "metadata": {},
   "source": [
    "# Vaccine Allotment Code Demonstration\n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making. In these models, a principal interacts with a system having stochastic transitions and rewards and aims to control the system online (by exploring available actions using real-time feedback) or offline (by exploiting known properties of the system).\n",
    "\n",
    "This project revolves around providing a unified landscape on scaling reinforcement learning algorithms to operations research domains.\n",
    "\n",
    "In this notebook we walk through generating plots, and applying the problem to the `vaccine allotment` problem with a population of size $P$ split into four risk classes, a discrete state space $\\mathcal{S} = \\{0, 1, 2, \\ldots, P\\}^{11}$, and a discrete action space consisting of \"priority orders\" corresponding to how we allot vaccines to the four risk classes. In this case, a valid priority order is one of two options: \n",
    "1. an empty list -- interpreted as no priority order, meaning we vaccinate the population randomly\n",
    "2. a permutation of the numbers $\\{1,2,3,4\\}$ -- interpreted as the order in which we vaccinate the risk classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-origin",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Packages\n",
    "\n",
    "The main package for ORSuite is contained in `or_suite`.  However, some additional packages may be required for specific environments / algorithms.  Here, we include `stable baselines`, a package containing implementation for state of the art deep RL algorithms, and `matploblib` for the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quick-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-clark",
   "metadata": {},
   "source": [
    "### Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "generic-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG = or_suite.envs.env_configs.vaccine_4groups_default_config\n",
    "epLen = DEFAULT_CONFIG['epLen']\n",
    "nEps = 200\n",
    "numIters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-glossary",
   "metadata": {},
   "source": [
    "### Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation.  This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unnecessary-starter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5}\n",
    "\n",
    "vaccine_env = gym.make('Vaccine-v0', config=DEFAULT_CONFIG)\n",
    "mon_env = Monitor(vaccine_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-penguin",
   "metadata": {},
   "source": [
    "### Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `random` policy, and some `RL discretization based` algorithms.  Here we pick a couple of the heuristics, and a PPO algorithm implemented from `stable baselines` just to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "according-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayleencortez/anaconda3/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py:132: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 4`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 4\n",
      "We recommend using a `batch_size` that is a multiple of `n_steps * n_envs`.\n",
      "Info: (n_steps=4 and n_envs=1)\n",
      "  f\"You have specified a mini-batch size of {batch_size},\"\n"
     ]
    }
   ],
   "source": [
    "agents = {'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "          'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-coaching",
   "metadata": {},
   "source": [
    "### Step 5: Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "significant-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'render'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2bfbee744ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dirPath'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/vaccine_metric_test_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SB PPO'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_sb_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single_algo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_SETTINGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Spring 2021/ORSuite/or_suite/utils.py\u001b[0m in \u001b[0;36mrun_single_sb_algo\u001b[0;34m(env, agent, settings)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msb_experiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSB_Experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mdt_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Spring 2021/ORSuite/or_suite/experiment/sb_experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, model, dict)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'numIters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_trajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'saveTrajectory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'render'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'render'"
     ]
    }
   ],
   "source": [
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/vaccine_metric_test_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(mon_env, agents[agent], DEFAULT_SETTINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-funds",
   "metadata": {},
   "source": [
    "### Step 6: Generate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_line = []\n",
    "algo_list_radar = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(str(agent))\n",
    "    path_list_line.append('../data/vaccine_metric_test_'+str(agent)+'/data.csv')\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':    \n",
    "        path_list_radar.append('../data/vaccine_metric_test_'+str(agent)+'/')\n",
    "        algo_list_radar.append(str(agent))\n",
    "\n",
    "    \n",
    "\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'test_vaccine_metric.pdf'\n",
    "\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40) + 1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y))}\n",
    "\n",
    "\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar, fig_path, fig_name, additional_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
