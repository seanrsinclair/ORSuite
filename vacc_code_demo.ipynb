{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frequent-passport",
   "metadata": {},
   "source": [
    "# Vaccine Allotment Code Demonstration\n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making. In these models, a principal interacts with a system having stochastic transitions and rewards and aims to control the system online (by exploring available actions using real-time feedback) or offline (by exploiting known properties of the system).\n",
    "\n",
    "This project revolves around providing a unified landscape on scaling reinforcement learning algorithms to operations research domains.\n",
    "\n",
    "In this notebook we walk through generating plots, and applying the problem to the `vaccine allotment` problem with a population of size $P$ split into four risk classes, a discrete state space $\\mathcal{S} = \\{0, 1, 2, \\ldots, P\\}^{11}$, and a discrete action space consisting of \"priority orders\" corresponding to how we allot vaccines to the four risk classes. In this case, a valid priority order is one of two options: \n",
    "1. an empty list -- interpreted as no priority order, meaning we vaccinate the population randomly\n",
    "2. a permutation of the numbers $\\{1,2,3,4\\}$ -- interpreted as the order in which we vaccinate the risk classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-origin",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Packages\n",
    "\n",
    "The main package for ORSuite is contained in `or_suite`.  However, some additional packages may be required for specific environments / algorithms.  Here, we include `stable baselines`, a package containing implementation for state of the art deep RL algorithms, and `matploblib` for the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quick-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-clark",
   "metadata": {},
   "source": [
    "### Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generic-transsexual",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'or_suite' has no attribute 'envs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-78445afe9c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDEFAULT_CONFIG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mor_suite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaccine_4groups_default_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mepLen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_CONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epLen'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnEps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnumIters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'or_suite' has no attribute 'envs'"
     ]
    }
   ],
   "source": [
    "DEFAULT_CONFIG = or_suite.envs.env_configs.vaccine_4groups_default_config\n",
    "epLen = DEFAULT_CONFIG['epLen']\n",
    "nEps = 200\n",
    "numIters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-glossary",
   "metadata": {},
   "source": [
    "### Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation.  This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unnecessary-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/ambulance/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters, \n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5}\n",
    "\n",
    "ambulance_env = gym.make('Ambulance-v0', config=DEFAULT_CONFIG)\n",
    "mon_env = Monitor(ambulance_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-penguin",
   "metadata": {},
   "source": [
    "### Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `random` policy, and some `RL discretization based` algorithms.  Here we pick a couple of the heuristics, and a PPO algorithm implemented from `stable baselines` just to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "according-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\seanr\\anaconda3\\envs\\orsuite\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:131: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 5\n",
      "We recommend using a `batch_size` that is a multiple of `n_steps * n_envs`.\n",
      "Info: (n_steps=5 and n_envs=1)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "agents = {'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "          'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "          'Stable': or_suite.agents.ambulance.stable.stableAgent(DEFAULT_CONFIG['epLen']),\n",
    "          'Median': or_suite.agents.ambulance.median.medianAgent(DEFAULT_CONFIG['epLen'])\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-coaching",
   "metadata": {},
   "source": [
    "### Step 5: Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "significant-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "     episode  iteration  epReward      time    memory\n",
      "0        0.0        0.0 -3.992157 -1.935468  528939.0\n",
      "1        1.0        0.0 -3.293304 -2.687384  528939.0\n",
      "2        2.0        0.0 -2.481742 -3.522500  528939.0\n",
      "3        3.0        0.0 -2.659202 -3.456917  528939.0\n",
      "4        4.0        0.0 -3.075968 -3.365957  528939.0\n",
      "..       ...        ...       ...       ...       ...\n",
      "995    195.0        4.0 -1.339041 -3.425642   53762.0\n",
      "996    196.0        4.0 -1.726129 -3.505733   53762.0\n",
      "997    197.0        4.0 -0.891938 -3.456910   53762.0\n",
      "998    198.0        4.0 -0.825988 -3.489179   53762.0\n",
      "999    199.0        4.0 -1.918325 -3.489156   53762.0\n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "Writing to file ../data/ambulance_metric_test_SB PPO/data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "Random\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.87487178e+00  1.62523000e+05\n",
      "  -5.99067903e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00 -1.73130921e+00  3.91300000e+03\n",
      "  -6.90663629e+00]\n",
      " [ 2.00000000e+00  0.00000000e+00 -9.18083623e-01  3.09400000e+03\n",
      "  -6.90592209e+00]\n",
      " ...\n",
      " [ 1.97000000e+02  4.00000000e+00 -2.13506269e+00  4.55000000e+03\n",
      "  -7.60002165e+00]\n",
      " [ 1.98000000e+02  4.00000000e+00 -1.48253571e+00  4.55000000e+03\n",
      "  -7.60049818e+00]\n",
      " [ 1.99000000e+02  4.00000000e+00 -8.71981293e-01  4.55000000e+03\n",
      "  -7.60002165e+00]]\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "Stable\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seanr\\Documents\\GitHub\\ORSuite\\or_suite\\experiment\\experiment.py:119: RuntimeWarning: divide by zero encountered in log\n",
      "  self.data[index, 4] = np.log(((end_time) - (start_time)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "[[ 0.00000000e+00  0.00000000e+00 -8.51879284e-01  3.58400000e+03\n",
      "  -7.60097494e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00 -1.27596690e+00  1.55099000e+05\n",
      "  -7.59954535e+00]\n",
      " [ 2.00000000e+00  0.00000000e+00 -8.48246947e-01  2.57500000e+03\n",
      "             -inf]\n",
      " ...\n",
      " [ 1.97000000e+02  4.00000000e+00 -7.72291988e-01  3.76400000e+03\n",
      "             -inf]\n",
      " [ 1.98000000e+02  4.00000000e+00 -9.89294961e-01  1.27240000e+04\n",
      "  -7.60097494e+00]\n",
      " [ 1.99000000e+02  4.00000000e+00 -7.74680257e-01  3.76400000e+03\n",
      "             -inf]]\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n",
      "Median\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n",
      "**************************************************\n",
      "Experiment complete\n",
      "**************************************************\n",
      "**************************************************\n",
      "Saving data\n",
      "**************************************************\n",
      "[[ 0.00000000e+00  0.00000000e+00 -8.42854276e-01  1.60983000e+05\n",
      "  -5.99058374e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00 -1.11498478e+00  3.50400000e+03\n",
      "  -6.90735100e+00]\n",
      " [ 2.00000000e+00  0.00000000e+00 -7.51603201e-01  3.16800000e+03\n",
      "  -7.59906927e+00]\n",
      " ...\n",
      " [ 1.97000000e+02  4.00000000e+00 -6.24859601e-01  4.48000000e+03\n",
      "  -6.90782776e+00]\n",
      " [ 1.98000000e+02  4.00000000e+00 -7.87534729e-01  2.24000000e+04\n",
      "  -6.90687447e+00]\n",
      " [ 1.99000000e+02  4.00000000e+00 -7.13977367e-01  4.48000000e+03\n",
      "  -6.50156818e+00]]\n",
      "Writing to file data.csv\n",
      "**************************************************\n",
      "Data save complete\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/ambulance_metric_test_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(ambulance_env, agents[agent], DEFAULT_SETTINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-funds",
   "metadata": {},
   "source": [
    "### Step 6: Generate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aquatic-tracker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n",
      "Random\n",
      "Stable\n",
      "Median\n",
      "  Algorithm    Reward      Time   Space       MRT\n",
      "0    Random -1.291178 -7.380172  4578.8 -0.320382\n",
      "1    Stable -0.814626      -inf  3764.0 -0.183517\n",
      "2    Median -0.825112 -6.826338  4517.6 -0.132534\n"
     ]
    }
   ],
   "source": [
    "path_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_line = []\n",
    "algo_list_radar = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(str(agent))\n",
    "    path_list_line.append('../data/ambulance_metric_test_'+str(agent)+'/data.csv')\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':    \n",
    "        path_list_radar.append('../data/ambulance_metric_test_'+str(agent)+'/')\n",
    "        algo_list_radar.append(str(agent))\n",
    "\n",
    "    \n",
    "\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'test_ambulance_metric.pdf'\n",
    "\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40) + 1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y))}\n",
    "\n",
    "\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar, fig_path, fig_name, additional_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
