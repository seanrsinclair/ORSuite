{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5831d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mayleencortez/Desktop/Spring 2021/ORSuite/or_suite/envs/ambulance\n",
      "/Users/mayleencortez/Desktop/Spring 2021/ORSuite/or_suite/envs\n"
     ]
    }
   ],
   "source": [
    "import or_suite\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "CONFIG = or_suite.envs.env_configs.vaccine_4groups_default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91546506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making an instance of the environment\n",
    "env = gym.make('Vaccine-v0', config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b042c6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 990 1990  990 5990   10   10   10   10    0    0    0]\n",
      "Discrete(25)\n",
      "MultiDiscrete([10001 10001 10001 10001 10001 10001 10001 10001 10001 10001 10001])\n"
     ]
    }
   ],
   "source": [
    "print(env.state)\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9998d0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 854 1341  921 4823   71  357   11  573  178   69 1607]\n",
      "-1607.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# testing the step function\n",
    "newState, reward,  done, info = env.step(0)\n",
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fc5f989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 282   37  585 1502  313  801   56 1673  479  264 5100]\n",
      "-5100.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "newState, reward,  done, info = env.step(0)\n",
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14dba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  64    0  261  489  198  308   58  927  256  176 1167]\n",
      "-1167.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "newState, reward,  done, info = env.step(0)\n",
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a58540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20   0  73 133  72 100  27 374 110  81 149]\n",
      "-149.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "newState, reward,  done, info = env.step(0)\n",
    "print(newState)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-passport",
   "metadata": {},
   "source": [
    "# Vaccine Allotment Code Demonstration\n",
    "\n",
    "Reinforcement learning (RL) is a natural model for problems involving real-time sequential decision making. In these models, a principal interacts with a system having stochastic transitions and rewards and aims to control the system online (by exploring available actions using real-time feedback) or offline (by exploiting known properties of the system).\n",
    "\n",
    "This project revolves around providing a unified landscape on scaling reinforcement learning algorithms to operations research domains.\n",
    "\n",
    "In this notebook we walk through generating plots, and applying the problem to the `vaccine allotment` problem with a population of size $P$ split into four risk classes, a discrete state space $\\mathcal{S} = \\{0, 1, 2, \\ldots, P\\}^{11}$, and a discrete action space consisting of \"priority orders\" corresponding to how we allot vaccines to the four risk classes. In this case, a valid priority order is one of two options: \n",
    "1. an empty list -- interpreted as no priority order, meaning we vaccinate the population randomly\n",
    "2. a permutation of the numbers $\\{1,2,3,4\\}$ -- interpreted as the order in which we vaccinate the risk classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-origin",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Packages\n",
    "\n",
    "The main package for ORSuite is contained in `or_suite`.  However, some additional packages may be required for specific environments / algorithms.  Here, we include `stable baselines`, a package containing implementation for state of the art deep RL algorithms, and `matploblib` for the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "quick-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import or_suite\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-clark",
   "metadata": {},
   "source": [
    "### Step 2: Pick problem parameters for the environment\n",
    "\n",
    "Here we use the ambulance metric environment as outlined in `or_suite/envs/ambulance/ambulance_metric.py`.  The package has default specifications for all of the environments in the file `or_suite/envs/env_configs.py`, and so we use one the default for the ambulance problem in a metric space.\n",
    "\n",
    "In addition, we need to specify the number of episodes for learning, and the number of iterations (in order to plot average results with confidence intervals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "generic-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG = or_suite.envs.env_configs.vaccine_4groups_default_config\n",
    "epLen = DEFAULT_CONFIG['epLen']\n",
    "nEps = 200\n",
    "numIters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-glossary",
   "metadata": {},
   "source": [
    "### Step 3: Pick simulation parameters\n",
    "\n",
    "Next we need to specify parameters for the simulation.  This includes setting a seed, the frequency to record the metrics, directory path for saving the data files, a deBug mode which prints the trajectory, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unnecessary-starter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DEFAULT_SETTINGS = {'seed': 1, \n",
    "                    'recFreq': 1, \n",
    "                    'dirPath': '../data/vaccine/', \n",
    "                    'deBug': False, \n",
    "                    'nEps': nEps, \n",
    "                    'numIters': numIters,\n",
    "                    'render': False,\n",
    "                    'saveTrajectory': True, \n",
    "                    'epLen' : 5}\n",
    "\n",
    "vaccine_env = gym.make('Vaccine-v0', config=DEFAULT_CONFIG)\n",
    "mon_env = Monitor(vaccine_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-penguin",
   "metadata": {},
   "source": [
    "### Step 4: Pick list of algorithms\n",
    "\n",
    "We have several heuristics implemented for each of the environments defined, in addition to a `random` policy, and some `RL discretization based` algorithms.  Here we pick a couple of the heuristics, and a PPO algorithm implemented from `stable baselines` just to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "according-graph",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayleencortez/anaconda3/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py:132: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 4`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 4\n",
      "We recommend using a `batch_size` that is a multiple of `n_steps * n_envs`.\n",
      "Info: (n_steps=4 and n_envs=1)\n",
      "  f\"You have specified a mini-batch size of {batch_size},\"\n"
     ]
    }
   ],
   "source": [
    "agents = {'SB PPO': PPO(MlpPolicy, mon_env, gamma=1, verbose=0, n_steps=epLen),\n",
    "          'Random': or_suite.agents.rl.random.randomAgent(),\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-coaching",
   "metadata": {},
   "source": [
    "### Step 5: Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5594f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "or_suite.utils.run_single_algo(mon_env, agents['Random'], DEFAULT_SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB PPO\n",
      "**************************************************\n",
      "Running experiment\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "for agent in agents:\n",
    "    print(agent)\n",
    "    DEFAULT_SETTINGS['dirPath'] = '../data/vaccine_metric_test_'+str(agent)+'/'\n",
    "    if agent == 'SB PPO':\n",
    "        or_suite.utils.run_single_sb_algo(mon_env, agents[agent], DEFAULT_SETTINGS)\n",
    "    else:\n",
    "        or_suite.utils.run_single_algo(mon_env, agents[agent], DEFAULT_SETTINGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-funds",
   "metadata": {},
   "source": [
    "### Step 6: Generate figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_line = []\n",
    "path_list_radar = []\n",
    "algo_list_line = []\n",
    "algo_list_radar = []\n",
    "\n",
    "for agent in agents:\n",
    "    print(str(agent))\n",
    "    path_list_line.append('../data/vaccine_metric_test_'+str(agent)+'/data.csv')\n",
    "    algo_list_line.append(str(agent))\n",
    "    if agent != 'SB PPO':    \n",
    "        path_list_radar.append('../data/vaccine_metric_test_'+str(agent)+'/')\n",
    "        algo_list_radar.append(str(agent))\n",
    "\n",
    "    \n",
    "\n",
    "fig_path = '../figures/'\n",
    "fig_name = 'test_vaccine_metric.pdf'\n",
    "\n",
    "or_suite.plots.plot_line_plots(path_list_line, algo_list_line, fig_path, fig_name, int(nEps / 40) + 1)\n",
    "\n",
    "additional_metric = {'MRT': lambda traj : or_suite.utils.mean_response_time(traj, lambda x, y : np.abs(x-y))}\n",
    "\n",
    "\n",
    "or_suite.plots.plot_radar_plots(path_list_radar, algo_list_radar, fig_path, fig_name, additional_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "retired-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "immune-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(vaccine_env, skip_render_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-sixth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
